{% extends "base.html" %}
{% block title %}
Centre for Computational Intelligence
{% endblock %}

{%block content %}
<main>
  <div
    style="background-image: url('../static/assets/img/Testimonial-bg.jpg'); background-position: top 80%; background-size: cover; width: 100%; height: 150px;">
    <h1 class="position-absolute ml-2" style="margin-top: 50px; color:white; margin-left: 120px;">Research</h1>
  </div>
  <div class="container d-flex flex-column m-auto m-5 p-5">
    <h2 class=' text-center'>Centre for Computational Intelligence (CCI)</h2>
    <div class="cell-md-12">

      <div class="list-order">
        <h5 class="text-center"></h5>
        <p class="lead text-center" style="text-align: center;">&nbsp;<img
            src="../static/assets/img/reseach6.jpg"
            alt="" width="120" height="160" /> &nbsp;</p>
        <p class="lead text-center" style="text-align: center;">Led by Dr Goh Ching Pang &nbsp; &nbsp;</p>
        <!-- Feature -->
        <p></p>
        <!-- <div class="jumbotron feature">--><!-- <div class="container">--><!-- <h3><span class="glyphicon glyphicon-equalizer"></span> Dramatically Engage</h3>--><!-- <p>Objectively innovate empowered manufactured products whereas parallel platforms.</p>--><!-- <p><a class="btn btn-primary" href="#">Engage Now</a></p>--><!-- </div>--><!-- </div>-->
        <div class="container">
          <div class="row">
            <div class="col-xs-12">
              <h4 class="text-center">What is Computational Intelligence ?</h4>
              <p class="lead text-center">It stands for a sub-domain of Artificial Intelligence that endows the ability
                for a computer or machine to learn and perform any intellectual task, similar to a human being.</p>
              <p></p>
              <h4 class="text-center">What we do ?</h4>
              <p class="lead text-center">To explore on designing algorithm and techniques that close to the
                human&rsquo;s way of reasoning, i.e. utilizes inexact and incomplete knowledge and performs control
                actions in an adaptive way. Image and video processing, data mining, natural language processing,
                artificial intelligence, computer vision processing, robotics and human computer interaction seek the
                similar goals with Computational Intelligence. It is a way of performing like human beings and most of
                the time heavily used to perform reasoning and decision making processes.</p>
              <p></p>
              <h4 class="text-center">What we aim for ?</h4>
              <p class="lead text-center">To research and integrate the nature-inspired intelligence methodologies into
                the computer systems to address the complex real-world problems.</p>
            </div>
          </div>
        </div>
        <!-- /.container-fluid -->
        <div class="container"><!-- Heading -->
          <div class="row">
            <div class="col-lg-12">
              <h4 class="page-header">Research Group&nbsp;-&nbsp;<small style="color: black;">located at Computational
                  Intelligence Research Laboratory, B001C (formally as B101), Block B, TAR UMT Main Campus</small></h4>
            </div>
          </div>
          <!-- /.row --> <!-- Projects Row -->
          <div class="row">
            <div class="col-md-3 portfolio-item h-100" style="text-align: center;"><a href="#"> <img class="p-2"
                  src="https://www.tarc.edu.my/files/focs/cci/5403F04D-9D56-4DA5-AFA8-0944EAD8CBEB.jpg" caption="false"
                  style="object-fit: cover; width: 300px; height: auto;"/> </a>
              <h5 class="text-center"><a href="#">Artificial Intelligence (AI) Group</a><p></p></h5>
              <p align="justify">Led by Dr Lim Khai Yin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img
                  src="../static/assets/img/reseach7.jpg"
                  width="60" height="80" caption="false"
                  style="float: center; margin-left: auto; margin-right: auto;" /></p>
              <p align="justify">AI is a general term that implies the use of computer to model and / or replicate
                intelligent behaviour. AI research focuses on the development and analysis of algorithms that learns and
                / or performs intelligent behaviour with minimal human intervention. These techniques have been and
                continue to be applied to a broad range of solution in robotics, e-commerce, medical diagnosis, gaming,
                mathematics, etc. Specifically, research is being conducted in estimation theory, mobility mechanism,
                active computer vision and so on.</p>
            </div>
            <div class="col-md-3 portfolio-item h-100" style="text-align: center;"><a href="#"> <img class="p-2"
                  src="https://www.tarc.edu.my/files/focs/84D90114-1237-4D2D-97F1-13D0376840E2.jpg" caption="false"
                  style="object-fit: cover; width: 300px; height: auto;"/> </a>
              <h5 class="text-center"><a href="#">Computer Vision (CV) Group</a><p></p></h5>
              <p align="justify">Led by AP Ts Dr Tew Yiqi&nbsp;&nbsp;&nbsp;&nbsp;<img
                  src="../static/assets/img/reseach8.jpg"
                  alt="" width="60" height="80" caption="false" /></p>
              <p align="justify">CV processing works on the computer-based interpretation of 2D and 3D image data set
                from conventional and nonconventional image sources. It involves the field of Medical Image Analysis,
                Visualization, Object recognition, Gesture Analysis, Facial Expression, Tracking and Scene understanding
                and modelling, etc.</p>
            </div>
            <div class="col-md-3 portfolio-item h-100" style="text-align: center;"><a href="#"> <img class="p-2"
                  src="https://www.tarc.edu.my/files/focs/990E2037-FAB6-4EBF-B24B-1750758ACCF8.jpg" caption="false"
                  style="object-fit: cover; width: 300px; height: auto;"/> </a>
              <h5 class="text-center"><a href="#">Robotic<br />Group</a></h5>
              <p align="justify">Led by Mr Wong Hon Yoon&nbsp;&nbsp;&nbsp;&nbsp;<img
                  src="../static/assets/img/reseach9.jpg"
                  width="60" height="80" caption="false"
                  style="float: center; margin-left: auto; margin-right: auto;" /></p>
              <p align="justify">Robotic research is involved in research pertaining to all aspects of robotic
                manipulation, controls and developing Socially Assistive Robots. Our primary focus is to engineer robots
                that can operate and interact with humans in unstructured environment. Furthermore, human motion and
                models development is focused. The current project is working on capturing elegant human motion, improve
                the system and robot programming in Python language.</p>
            </div>
            <div class="col-md-3 portfolio-item h-100" style="text-align: center;"><a href="#"> <img class="p-2"
                  src="https://www.tarc.edu.my/files/focs/E5AD03F5-4401-4595-9D78-73C25822E9F5.jpg" caption="false"
                  style="object-fit: cover; width: 300px; height: auto;"/> </a>
              <h5 class="text-center"><a href="#">Human Computer Interaction (HCI) Group</a></h5>
              <p align="justify">Led by Dr Aw Kien Sin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img
                  src="../static/assets/img/reseach10.jpg"
                  width="60" height="80" caption="false"
                  style="float: center; margin-left: auto; margin-right: auto;" /></p>
              <p align="justify">HCI group aims to bridge gap between the human and digital world. Thus, we explore the
                possibilities to reduce the gap by integrating emerging technologies (e.g., new affordance of the
                Internet of Things) into our interaction design and solution, with new affordances . Beside, human
                factors such as human behavior, cognitive psychology, culture, environment, etc will be taken into
                consideration during the design process, as human/users is the centre of this field of study.</p>
            </div>
          </div>
          <div class="row">
            <div class="col-lg-12">
              <h4 class="page-header">Achievement in the past</h4>
              <ul>Computational Intelligence Research Lab is working towards to set up the facilities and take
                opportunity for supporting innovative development through undergraduate final year projects, projects in
                postgraduate programmes offered by TAR UMT.
                <li align="justify"><span>2022: Enveloped Digital Document Recognition with Optical Character
                    Recognition (OCR) Technology by Dr Tew Yiqi (obtained RM 100,000 from TAR UMT internal grant)
                    &nbsp;</span></li>
                <li align="justify"><span>2020: Installation of high-end computer terminals and infrastructure for
                    Artificial Intelligence (AI) and Big Data Analytics (BDA) related Research and Development, talent
                    development and conducting public training or workshops by Dr Lim Yee Mei (obtained RM399k under
                    RMK11) &nbsp;</span></li>
                <li align="justify"><span>2020: Interactive Dashboard with Visual Sensing and Zero-shot Learning
                    Capabilities by Dr Chaw Jun Kit and Dr Tew Yiqi (obtained RM58,200 from TAR UMT internal grant)
                    &nbsp;</span></li>
                <li align="justify"><span>2020: Smart Autonomous Drone System for Building Inspections by Ts Ong Jia Hui
                    (obtained RM 4,000 from Hilti (Malaysia) Sdn Bhd) &nbsp;</span></li>
                <li align="justify"><span>2019: Obtained competition award from Hilti (malaysia) Sdn Bhd on the project
                    title: Building Condition Evaluation through Crack Detection, by Dr Chaw Jun Kit and a final year
                    project student (obtained RM 4,000 industrial grant) &nbsp;</span></li>
                <li align="justify"><span>2019: Collaborated with Asia Roofing Industries Sdn Bhd on the project title:
                    Intelligent Materials and Manufacturing Planning System, by Dr Chaw Jun Kit and a postgraduate
                    student (obtained RM 92,000 industrial grant) &nbsp;</span></li>
                <li align="justify"><span>2018: Collaborated with Hotayi Electronic (M) Sdn Bhd in Image Processing
                    Automation (Optical Character Recognition) and Parts Supply Chain Automation (Purchase Order
                    Matching System), by Ts Dr Tew Yiqi, Ms Choon Kwai Mui, and a team of Final Year Project students
                    (obtained RM100,000 industrial grant, co-work with another 4 FOCS and FOET projects) &nbsp;</span>
                </li>
                <li align="justify"><span>2018: Collaborated with Kian Joo Can Factory Berhad on the project title:
                    Intelligent Materials and Manufacturing Planning System, by Dr Lim Yee Mei and a postgraduate
                    student (obtained RM 92,000 industrial grant) &nbsp;</span></li>
                <li align="justify"><span>2018: Obtained Fundamental Research Grant Scheme (FRGS) in the area of HEVC
                    Multiview Video Streaming Mechanism for Data Distribution Service Framework, by Ts Dr Tew Yiqi and a
                    postgraduate student (obtained RM 48,000 government grant) &nbsp;</span></li>
                <li align="justify"><span>2017: Co-Research with FOET lecturer in the area of Micro-Expression
                    Recognition via Fundamental Research Grant Scheme (FRGS) by Dr Lim Chern Hong&nbsp; </span></li>
                <li align="justify"><span>2017: Participated in PECIPTA 2017 to showcase Smart Classroom Management and
                    Car Plate Recognition System and won bronze medals by Dr Lim Chern Hong&nbsp;</span></li>
              </ul>
            </div>
          </div>
          <div class="row">
            <div class="col-lg-12">
              <h4 class="page-header">Projects&nbsp;-&nbsp;<small style="color: black;">Recent Work</small></h4>
            </div>
          </div>
          <!-- Projects Row -->
          <div class="container-fluid"><!-- Project One -->
            <div class="row">
              <div class="col-md-4"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/7813F3E6-3968-4452-B7F8-E32720920FF7.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h5>Brain Tumor Classification</h5>
                <p align="justify">Brain tumor is a group of abnormal cells in the brain which can be either cancerous
                  (malignant) or non-cancerous (benign). Gliomas are the most common brain tumor that can be categorized
                  into low-grade glioma (LGG) and high-grade glioma (HGG). Identifying the location and area of the
                  tumor has been a tedious job for radiologists, let alone to classify the tumor into the LGG / HGG.
                  Hence, a fully automatic approach is proposed to segment the brain tumor in Magnetic Resonance Imaging
                  (MRI) images and classify it into the LGG / HGG. A high bias algorithm 3D Convolutional Neural-network
                  (CNN) is employed to segment the brain tumor into edema, necrotic, and enhancing tumor. The segmented
                  tumor is then used to generate the radiomics features and the Support Vector Machine (SVM) is used to
                  classify the LGG and HGG tumor. This work is tested on Brats 2017 and the experiments show promising
                  results with the Dice scores, for segmentation and classification for LGG and HGG, at 0.85 Dice Scores
                  and 0.83 F1-Score, respectively. <a class="btn btn-link" href="#">View Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Two -->
            <div class="row">
              <div class="col-md-4"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/3D86039C-8291-4993-807E-1DE3EF74423E.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h5>Crack Detection System</h5>
                <p align="justify">Reinforced concretes and cement based materials are used to construct buildings and
                  civil structures. The building conditions are prone to environmental exposure and loadings factor that
                  can cause cracks on the surface. To prevent the expansion of harm, effective treatment requires first
                  the understanding of the cracking root cause, and then, a strategy for repair is implemented.
                  Traditional approach of manual crack detection requires more effort and time. In this project, an
                  automated vision-based crack detection system using deep learning framework is developed to assist the
                  repair work in the term of resource planning. The encoder-decoder architecture in the deep learning
                  framework produces convolutional features that improve the performance of image segmentation where the
                  cracks can be differentiated from the background more effectively. <a class="btn btn-link"
                    href="#">View Project</a></p>
              </div>
            </div>
            <hr />
            <div class="row">
              <h5>Intelligent Scene Detection</h5>
              <p align="justify">The team has generalized most of the object detection works, including exploration on
                various machine learning algorithm to a deployable prototype solution under different case scenario and
                camera view scene, to serve a specific business objectives. For instance: <a class="btn btn-link"
                  href="https://sites.google.com/tarc.edu.my/focs-cci-class">Go to Projects' Page</a></p>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Three -->
            <div class="row">
              <div class="col-md-3"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/6BB21769-BB56-48E1-A217-DC79A4018068.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h6>Intelligent Classroom System</h6>
                <p align="justify">Artificial intelligent processing in video technology is growing rapidly, such as
                  face identification and behaviour analysis. This project utilizes face identification features to
                  process multiple camera views, update students&rsquo; attendance to a cloud database and implement
                  Anomaly Activity Detection Module. It constantly tracks the students&rsquo; whereabouts and publish
                  the updates of the students&rsquo; status to the same cloud database. In this project, ten test faces
                  are detected, identified and recorded in database based on the trained dataset with high accuracy
                  within an acceptable time frame across multiple camera views under certain conditions.<br /><a
                    class="btn btn-link" href="https://sites.google.com/tarc.edu.my/focs-cci-class/multiple-camera">View
                    Project 1</a> <a class="btn btn-link"
                    href="https://sites.google.com/tarc.edu.my/focs-cci-class/iot">View Project 2</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Four -->
            <div class="row">
              <div class="col-md-3"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/8D1E5A0F-076C-4C90-832F-CE6D2AADBD73.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h6>Deviant Scene Detection</h6>
                <p align="justify">Most of the organizations (e.g., educational institutions, manufacturing factories
                  etc.) in Malaysia require supervisors or managers to monitor participants (e.g., workers) during the
                  operating hours in order to ensure that participants comply with the rules and regulation. This
                  project is expected to reduce the human effort in monitoring participants by replacing it with an
                  intelligent camera that is able to detect abnormal activity. The way to implement this is to utilize
                  the camera surveillance in the operation area by adopting technology such as artificial intelligence
                  (AI), machine learning (ML), image & video processing or computer vision (CV) and Internet of Things
                  (IoT) to learn and detect human activities/behaviours. <a class="btn btn-link"
                    href="https://sites.google.com/tarc.edu.my/focs-cci-class/deviant-detector">View Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Five-->
            <div class="row">
              <div class="col-md-3"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/F6F06433-D852-46F4-9F1E-2876B53739C7.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h6>Face Mask and Social Distancing Detection</h6>
                <p align="justify">Face masks have recently been a symbol of the global battle to prevent COVID-19
                  spread. The project is expected to develop an higher accuracy face recognition model to recognize
                  human face with and without mask. Secondly, social distancing detector is to monitor if save distance
                  is practised among people in public. Thirdly, face mask detection is to detect high-risk situations
                  without proper mask. These technique can be used in various settings to assist decrease illness
                  spread, such as classrooms, stores, and factories. <a class="btn btn-link"
                    href="https://sites.google.com/tarc.edu.my/focs-cci-class/face-mask-social-distance">View
                    Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Six-->
            <div class="row">
              <div class="col-md-3"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/05E60DCC-04A9-44EE-AFF1-1956A99C3A0B.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h6>Virtual Classroom Monitoring</h6>
                <p align="justify">The advancement of computer technology allows students to interact with educators
                  using Artificial Intelligence (AI) technology through smart classrooms (E-Learning Classrooms).
                  Currently, smart classrooms are believed to change the existing dull teaching methods and enhance the
                  students&rsquo; learning experience. Therefore, the proposed system offers real-time users performance
                  monitoring features such as detection and recognition on face and hand gesture to monitor student
                  activities and recognize student behaviour through the smart classrooms. <a class="btn btn-link"
                    href="https://sites.google.com/tarc.edu.my/focs-cci-class/virtual-classroom">View Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Seven-->
            <div class="row">
              <div class="col-md-3"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/91AF0EBF-A9AF-4414-8DDC-DABDD9AC52C1.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h6>Zero-Shot Learning on Human Action and Gesture Detection</h6>
                <p align="justify">The Zero-shot Leaning module in an object detection process observes an input (e.g.,
                  video scene) is not being trained, and predicts its detected category. The team has applied this
                  approach in a gesture-based human machine interaction (HCI) prototype solution. HCI studies
                  continually emphasize the user experience especially when it is implemented in a real-world
                  environment. As known that every individual acts differently and more uncontrollable environmental
                  variables might affect the performance to detect and react to the gesture performed. Even though there
                  are many solutions and datasets proposed in the market, not each of them perfectly fitted to our
                  needs. Hence, to propose a more tailored made gesture detection for own use, the existing zero-shot
                  learning model will be tested on the gesture dataset introduced in this work to fine tune to own
                  needs. <a class="btn btn-link"
                    href="https://sites.google.com/tarc.edu.my/focs-cci-class/zero-shot-learning/zsl-on-gesture-movement-for-interactive-dashboard-control">View
                    Project</a></p>
              </div>
            </div>
            <hr />
            <div class="row">
              <h5>Augmented Reality Exploration</h5>
              <p align="justify">The team has put in additional efforts on realizing a computer vision effect into the
                era of virtual reality + physical world = Augmented Reality (AR). As one of the key pillars of realizing
                Industry 4.0, several AR application has been explored, developed and deployed to achieve different
                creative ideations and solutions. For instance: <a class="btn btn-link"
                  href="https://sites.google.com/tarc.edu.my/focs-cci-ar/">Go to Projects' Page</a></p>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Eight-->
            <div class="row">
              <div class="col-md-3"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/1AF9EB8A-39D7-4AE4-880B-5775C2C236CE.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h6>AR Furniture with 3D model captions</h6>
                <p align="justify">AR is one of the latest technologies that involves the integration of computer
                  graphics with the user&rsquo;s environment in real time. The proposed project is an AR mobile
                  application which offers preview of furniture in one&rsquo;s real environment by allowing the
                  consumers to visualize how the particular furniture will look in the real world using a smartphone
                  before they make a payment. To construct the furniture into a virtual object which is the 3D model
                  file, photogrammetry is applied as it is able to perform 3D construction using a batch of images
                  captured by the smartphone. When the construction is completed, the 3D model file will be converted
                  into a manifest file and is ready to be uploaded to the cloud. In the system, whenever a user selects
                  a model, the target model will be downloaded and markerless tracking will be activated to render the
                  model in the user&rsquo;s environment without a marker. <a class="btn btn-link"
                    href="https://sites.google.com/tarc.edu.my/focs-cci-ar/ar-furniture">View Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Nine-->
            <div class="row">
              <div class="col-md-3"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/120C8E48-193F-4937-B49D-6503698BEB4F.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h6>AR Shoes with 3D model reconstruction</h6>
                <p align="justify">AR technology brings digital information and virtual objects into the physical space.
                  With AR, the digital world comes to life inside the view captured by our tablet or phone camera. The
                  objective of this project to be achieved is to enable the user to construct 3D shoe models without
                  redesigning the 3D shoe models that they wanted to display in the AR application. Besides that, this
                  project is used to try on the 3D shoe models virtually by using the AR technology. The purpose of this
                  project is to let users try on the shoes more conveniently. They can just use their mobile phone to
                  try on the shoes virtually anywhere and anytime. <a class="btn btn-link"
                    href="https://sites.google.com/tarc.edu.my/focs-cci-ar/ar-shoes-new">View Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Ten-->
            <div class="row">
              <div class="col-md-4"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/B53CC2F7-2E77-40F8-8F59-DAEB39E84444.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h5>Visual Search Tool for E-commerce</h5>
                <p align="justify">This project aims to develop a mobile app for E-commerce with better customer
                  experience. Hence, instance-based image retrieval is integrated into this app to help customers to
                  search for similar products captured by them. This is especially useful for elderly people who may not
                  be too tech savvy. It allows them to snap an image to find desired products instead of typing the
                  product&rsquo;s name. Image search is an option in the standard search box, allowing the user to snap
                  a photo or select a photo from the camera roll to search. Then, it will sift through over items
                  available in the product catalogue to find similar products. <a class="btn btn-link" href="#">View
                    Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Eleven-->
            <div class="row">
              <div class="col-md-4"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/F995E53F-546B-4B54-AF60-622AB819A4CA.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h5>Care-U Application</h5>
                <p align="justify">Nowadays are exposed to both external and internal stress and more often than not,
                  they deny its existence and take on destructive ways to deal with it. Counseling service in
                  universities is generally not the first option nor the preference of the students as the satisfaction
                  of realization of them now comes from social media. In this work, a mobile application inclusive of a
                  Chatbot with sentiment analysis, blog and music sharing, and an interactive game was developed. This
                  application serves as a platform for the students to share their thoughts freely where they would be
                  comfortable being themselves. <a class="btn btn-link" href="#">View Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Twelve-->
            <div class="row">
              <div class="col-md-4"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/F01E551A-5646-4F0A-B459-4A2EEE1CE7C7.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h5>Cost Optimisation with Industrial Machine Performance</h5>
                <p align="justify">This project studies the production of a single type of product on multiple parallel
                  machines by a manufacturer. The manufacturer has a pool of machines available with a combined
                  production capacity greater than is required for production requirements. We assume that machine
                  productivity may vary within a given range, which gives manufacturers the opportunity to adjust their
                  total production capacity to meet demand and utilise the different cost structures of available
                  machines. In this case, the manufacturer must decide which machine to choose to generate a given
                  requirement and how to operate the machine. This project presents a deterministic mathematical model
                  to support the production and distribution planning scenario. <a class="btn btn-link" href="#">View
                    Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Thirtheen-->
            <div class="row">
              <div class="col-md-4"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/BBB40CB2-9082-4819-977A-85374E8BDF9D.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h5>Image Processing Automation and PO Matching System</h5>
                <p align="justify">Nowadays, companies often process invoices, order forms, and other paperwork
                  frequently. They are not satisfied with those common OCR technology to have only conversion of images
                  into texts and look forward to having text recognition on required information from the documents and
                  extract them out for validation purposes. The designed system is able to provide auto-validation for
                  the documents such as Purchase Order (PO), invoice, and Delivery Order (DO). It aims to produce a
                  customized OCR application for companies that could process different types of documents, retrieve the
                  required information and perform auto validation. Besides that, this system is developed to provide
                  functions such as data extraction and auto validation to various types of documents in order to reduce
                  human involvement. The creating template features was also implemented to deal with any kinds of new
                  documents in the future. By continuing to improve this project, the project is able to reach a
                  satisfied accuracy level and be ready for real life implementation. <a class="btn btn-link"
                    href="#">View Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- Project Fourteen-->
            <div class="row">
              <div class="col-md-4"><a href="#"> <img class="img-fluid rounded mb-3 mb-md-0"
                    src="https://www.tarc.edu.my/files/focs/cci/7B8E64DC-0734-4C27-B4D4-B927CA38815C.png" alt="" /> </a>
              </div>
              <div class="col-md-8">
                <h5>High Efficiency Video Coding in Industry 4.0</h5>
                <p align="justify">The demand for multi-view (MV) has increased rapidly and there was a lot of research
                  work to improve the technique and fulfil its needs. High Efficiency Video Coding (HEVC) compression
                  standard has been implemented in this work. HEVC is a compression standard designed to reduce bitrate
                  and remain the same quality compared to the previous compression standard Advanced Video Coding
                  (H.264). It will provide a better compression to higher resolution video such as Ultra High Definition
                  (UHD). In this paper present a preliminary study on MV with depth by using HEVC compression on a
                  real-time streaming protocol. The study of proposed work may help the industry to enhance the viewing
                  experience by multiple camera capture and also resolve the data traffic issue to transmit UHD video.
                  MV & 3D-HEVC codec was also proposing to encode and decode in near real-time video streaming by
                  setting up a three different view of cameras with depth prototyping on higher performance CPU. Few
                  validation methods like BD-rate, time, QP and PSNR will be considered to be used to make a comparison
                  with simulcast real-time multiple views architecture in difference HEVC extension. <a
                    class="btn btn-link" href="https://sites.google.com/tarc.edu.my/focs-cci-hevc">View Project</a></p>
              </div>
            </div>
            <!-- /.row -->
            <hr /><!-- /.row -->
          </div>
          <!-- /.row -->
          <p><span style="color: #0000ff;"><strong>Environmental Sustainability Publications</strong></span></p>
          <!-- /.container -->
          <ol>
            <li>TAN CHI WEE.&nbsp;A Prototype of Traffic Light Colour Detection Using Convolutional Neural Network (CNN)
              Algorithm. SDG11</li>
            <li>TAN CHI WEE. Flower Recognition Model based on Deep Neural Network with VGG19. SDG15</li>
            <li>TAN CHI WEE. Deep Learning & Hybrid Model - The Future of Medical Image Watermarking. SDG11</li>
            <li><a href="https://doi.org/10.54552/v82i3.116" target="_blank" rel="noopener noreferrer">TEW YIQI. An
                Evaluation of Virtual Classroom Performance with Artificial Intelligence Components. SDG11</a></li>
          </ol>
          <hr />
          <p></p>
        </div>
      </div>
    </div> <!-- // class sideMenu -->
  </div>
</main>
{%endblock %}